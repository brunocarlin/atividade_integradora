
# Atividade Integradora

Membros

* Bruno  
* Henrique  
* Yuri
  
## Set Up chuncks
```{r setup}
knitr::opts_chunk$set(
	echo = TRUE,
	message = FALSE,
	warning = FALSE
	)
```

```{r}
library(reticulate)
```


## Importação das principais bibliotecas que serão utilizadas

```{python}
import pandas as pd
import numpy as np
```

## Criação do dataframe utilizando o pandas como bilbioteca de manipulação de bases

```{python}
df1 = pd.read_feather("BD_PRE.feather")
```

## Describe 

```{python}
df1.describe()
```

## Realizar o drop das colunas que não serão utilizadas no modelo (IDTNS,TIPO,OPERADORA,ESTADO,DATA,H0,Q1,Q2,Q3,Q4,Q5,Q7)

### As variáveis foram retiradas por possuírem valores categóricos e únicos que não seriam interessantes para análise. Pois, sem variância destas features não agregariam em nada para o modelo.

```{python}
df1=df1.drop(["IDTNS","TIPO","DATA","H0","Q1","Q2","Q3","Q4","Q6","Q7"],axis=1)

df1.head()
```

## Renomeação da coluna J1 para target facilitando a análise da base

```{python}
df1 = df1.rename(columns = {'J1':'Target'})
```

```{python}
df1.head()
```

## Realizando a limpeza da base de acordo com o metadados disponibilizada no site do governo. Para cada variável foi feita uma manipulação de dados, no caso abaixo para toda variável em que o valor era 99 foi definida que esta seria missing. 

```{python}
df2 =  df1.copy()
```

```{python}
df2['B1_1'].replace([99], np.NaN,inplace = True)
df2['B1_2'].replace([99], np.NaN,inplace = True)
df2['C1_1'].replace([99], np.NaN,inplace = True)
df2['C1_2'].replace([99], np.NaN,inplace = True)
df2['D2_1'].replace([99], np.NaN,inplace = True)
df2['D2_2'].replace([99], np.NaN,inplace = True)
df2['D2_3'].replace([99], np.NaN,inplace = True)
df2['F5'].replace([99], np.NaN,inplace = True)
df2['F4'].replace([99], np.NaN,inplace = True)
df2['F2'].replace([99], np.NaN,inplace = True)
df2['A5'].replace([99], np.NaN,inplace = True)
df2['A4'].replace([99], np.NaN,inplace = True)
df2['A3'].replace([99], np.NaN,inplace = True)
df2['A2_1'].replace([99], np.NaN,inplace = True)
df2['A2_2'].replace([99], np.NaN,inplace = True)
df2['A2_3'].replace([99], np.NaN,inplace = True)
df2['E1_1'].replace([99], np.NaN,inplace = True)
df2['E1_2'].replace([99], np.NaN,inplace = True)
df2['E1_3'].replace([99], np.NaN,inplace = True)
df2['F4'].replace([99], np.NaN,inplace = True)
df2['F5'].replace([99], np.NaN,inplace = True)
df2['F6'].replace([99], np.NaN,inplace = True)
```

## Mesmo caso anterior, porém para os outros casos de valores considerados como missing.

```{python}
df2['Q8'].replace([999999], np.NaN,inplace = True)
df2['H1'].replace([99,99999], np.NaN,inplace = True)
df2['H2'].replace([99997,99998,99999,100000,999998,999999], np.NaN,inplace = True)
```

## A feature H2a foi removida, pois logo após seria criada um novo range de valores de salários nomeada como RIQUEZA

```{python}
df2.drop(["H2a"],inplace = True,axis = 1)
```

```{python}
df3 = df2.copy()
```

```{python}
df3.loc[(df3["H2"] >=0) & (df3["H2"] <1000), "RIQUEZA"]=1
df3.loc[(df3["H2"] >=1000) & (df3["H2"] <3000), "RIQUEZA"]=2
df3.loc[(df3["H2"] >=3000) & (df3["H2"] <6000), "RIQUEZA"]=3
df3.loc[(df3["H2"] >=6000) & (df3["H2"] <10000), "RIQUEZA"]=4
df3.loc[(df3["H2"] >=10000) & (df3["H2"] <15000), "RIQUEZA"]=5
df3.loc[(df3["H2"] >=15000) & (df3["H2"] <20000), "RIQUEZA"]=6
df3.loc[(df3["H2"] >=20000), "RIQUEZA"]=7
```

```{python}
df3.RIQUEZA.value_counts(dropna =False)
```

## Target Variable

        No código abaixo, foi definida para os valores de 99 para a Target e logo após todas as linhas que continha Target iguais a missing foram removidas da análise. Além disso, foi criada uma nova variável Target2 definindo se a nota da operadora foi RUIM (0) ou se a nota foi BOA (1).

```{python}
df3['Target'].replace([99], np.NaN,inplace = True)

df3.loc[(df3["Target"] <=8) ,"Target2"]= 0
df3.loc[(df3["Target"] >8 ) ,"Target2"]= 1


df3.dropna(subset=['Target'],inplace = True)

```


```{python}
df3.describe()
```


Variaveis Categoricas Moda
Estado  
Operadora  
RIQUEZA  
Q9  
I1 
D1     
Q5    
F1
F3  
F5  
G1

Variaveis Categoricas Missing Explicito
A1_x

## No código abaixo identificamos que existiam features em que caso o valor estivesse como missing ele representava igual a 0.

```{python}
df3["A1_1"].fillna(0,inplace = True)
df3["A1_2"].fillna(0,inplace = True)
df3["A1_3"].fillna(0,inplace = True)
df3["A1_4"].fillna(0,inplace = True)
df3["F1"].fillna(0,inplace = True)
df3["F3"].fillna(0,inplace = True)
df3["F5"].fillna(0,inplace = True)
```

## Após a correção de todos os valores da base, o código abaixo definiu no dataframe se todas as variáveis que seriam categóricas.

```{python}
df3['Q9'] = df3['Q9'].astype('category')
df3['I1'] = df3['I1'].astype('category')
df3['D1'] = df3['D1'].astype('category')
df3['Q5'] = df3['Q5'].astype('category')
df3['F1'] = df3['F1'].astype('category')
df3['F3'] = df3['F3'].astype('category')
df3['F5'] = df3['F5'].astype('category')
df3['G1'] = df3['G1'].astype('category')
df3["A1_1"] =  df3['A1_1'].astype('category')
df3["A1_2"] =  df3['A1_2'].astype('category')
df3["A1_3"] =  df3['A1_3'].astype('category')
df3["A1_4"] =  df3['A1_4'].astype('category')
df3["RIQUEZA"] =  df3['RIQUEZA'].astype('category')
df3["Target2"] =  df3['Target2'].astype('category')
```





```{python}
df3.dtypes
```

## Realizar a importação dos modelos que serão utilizados

```{python}
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
```

## Separação da base de dados em features e Target

Para as variáveis que dependiam da resposta de outras, estas foram retiradas da análise. Desta forma, foram apenas contempladas as variáveis que seja indepedentes de outras.

```{python}
df4=df3.loc[:,['Q5','Q8','Q8a','Q9','B1_1','B1_2','C1_1','C1_2','D1','D2_1','D2_2','D2_3','E1_1','E1_2','E1_3','A1_1','A1_2','A1_3','A1_4','F1','F3','F5','G1','H1','I1','PESO','RIQUEZA',"Target2"]]
```

```{r}
df <- py$df4
```

# Inicio R

```{r}
library(DataExplorer)
library(tidyverse)
library(tidymodels)
library(furrr)
library(h2o)
library(DALEX)
library(iBreakDown)
library(ingredients)
```

```{r}
DataExplorer::introduce(df)
```

```{r}
DataExplorer::plot_intro(df)
```

```{r}
plot_missing(df)
```

```{r}
df <- df %>% 
  select(-starts_with("D2"))
```

```{r}
plot_missing(df)
```

```{r}
#df <- df %>% 
#  mutate(RIQUEZA = RIQUEZA %>% fct_explicit_na())
```

```{r}
  df <- df %>% 
  rename(response = Target2) %>% 
  select(-PESO)
```

```{r}
  df2 <- df %>% 
  mutate(response = response %>% fct_recode(bad = "0",good ="1"))
```

```{r}
df2 %>% 
  count(response) %>%
  ggplot(aes(response, n, fill = response)) + 
  geom_col(width = .5, show.legend = FALSE) + 
  scale_y_continuous(labels = scales::comma) +
  scale_fill_manual(values = c("red","blue")) +
  labs(
    x = NULL,
    y = NULL,
    title = "Distribution of cases"
  )
  
```


# Modelagem

```{r}
telefone_initial_split <- df %>% rsample::initial_split(prop = 0.9)
telefone_initial_split
```

```{r}
train_data <- training(telefone_initial_split)
test_data <- testing(telefone_initial_split)
```

```{r}
recipe_telefone <- 
  recipe(response ~.,data = train_data) %>%
  #step_upsample(response,skip = TRUE) %>% 
  step_normalize(all_numeric()) %>%
  step_modeimpute(all_predictors(),-all_numeric()) %>% 
  step_medianimpute(all_predictors(),-all_nominal()) #%>% 
  #step_dummy(all_predictors(),-all_numeric())
```



```{r}
recipe_telefone %>% prep(retain = TRUE)
```

## Logistic

```{r}
simple_model_recipe <- recipe_telefone %>%
  prep(retain = TRUE)

simple_train <- simple_model_recipe %>% juice()

simple_test <- simple_model_recipe %>% bake(test_data)

logistic_regression <- 
  logistic_reg(mode = "classification",penalty = 0) %>%
  set_engine("glmnet") %>% 
  fit(response ~.,data = simple_train)

logistic_regression %>% 
  predict(simple_test) %>% 
  bind_cols(simple_test %>% select(response)) %>% 
  metrics(truth = response,estimate = .pred_class)

logistic_regression %>% 
  predict(simple_test,type = "prob") %>% 
  bind_cols(simple_test %>% select(response)) %>% 
  roc_auc(truth = response,predictor =.pred_0)
```

## Lasso

```{r}
lasso_regression <- logistic_reg(mode = "classification",mixture = 0) %>% 
  set_engine("glmnet") %>% 
  fit(response~ .,data = simple_train)

lasso_regression %>% 
  multi_predict(new_data = simple_test,type = "prob") %>% 
  bind_cols(simple_test) %>%
  unnest() %>% 
  group_by(penalty) %>% 
  do(ok = roc_auc(.,truth = response,predictor = .pred_0)) %>% 
  unnest() %>%
  spread(key = .metric,value = .estimate) %>%
  arrange(roc_auc %>% desc)
```

## Ridge

```{r}
ridge_regression <- logistic_reg(mode = "classification",mixture = 1) %>% 
  set_engine("glmnet") %>% 
  fit(response~ .,data = simple_train)

ridge_regression %>% 
  multi_predict(new_data = simple_test,type = "prob") %>% 
  bind_cols(simple_test) %>%
  unnest() %>% 
  group_by(penalty) %>% 
  do(ok = roc_auc(.,truth = response,predictor = .pred_0)) %>% 
  unnest() %>%
  spread(key = .metric,value = .estimate) %>%
  arrange(roc_auc %>% desc)
```

## Random Forest

```{r}
  random_forest <- rand_forest(mode = "classification",trees = 100) %>% 
  set_engine("ranger") %>% 
  fit(response~ .,data = simple_train)

random_forest %>% 
    predict(simple_test) %>% 
    bind_cols(simple_test %>% select(response)) %>% 
    metrics(truth = response,estimate = .pred_class)

random_forest %>% 
  predict(simple_test,type = "prob") %>% 
  bind_cols(simple_test %>% select(response)) %>% 
  roc_auc(truth = response,predictor =.pred_0)
```

## h2o

### Start CLuster

```{r}
library(h2o)
library(DALEXtra)
h2o.init(nthreads = 12,max_mem_size = "8g")
```


### Upload df's

```{r}
simple_train_hex <-  as.h2o(simple_train)
simple_test_hex = as.h2o(simple_test)
simple_y_hex <- simple_train %>% select(response) %>% pull %>% as.numeric()
simple_x_hex <- simple_train %>% select(-response)
```



### Fit auto ml

```{r}
aml <- h2o.automl(y = "response",
                  training_frame = simple_train_hex,
                  max_runtime_secs = 600,
                        seed = 1)
```

### Model results

```{r}
summary(aml)
```

```{r}
pred <- h2o.predict(aml, simple_test_hex)
pred
```

```{r}
aml@leaderboard
```

```{r}
model_ids <- as.data.frame(aml@leaderboard$model_id)[,1]
model_ids
```

### Using a stacked model

```{r}
best_h2o <- h2o.getModel(model_ids[model_ids %>% str_detect("StackedEnsemble_BestOfFamily_AutoML")])
```

```{r}
best_h2o
```

### Performance

```{r}
result_predictions <- predict(best_h2o,simple_test_hex)

result_predictions %>% 
  as_tibble() %>% 
  bind_cols(simple_test) %>% 
  metrics(truth = response,estimate = predict)

result_predictions %>% 
  as_tibble() %>% 
  bind_cols(simple_test) %>% 
  roc_auc(truth = response,predictor = p0)
```

# DALEX - Black Box?


## Dalex X e Y
```{r}
x_dalex <- simple_test %>% select(-response)
y_dalex <- simple_test %>%
  transmute(response = response %>%
              as.numeric()) %>% 
  mutate(response = if_else(response == 1,
                            0,
                            1)) %>% as.data.frame()
y_dalex <- y_dalex[,1]
```

## Model Performance

```{r}
explainer_h20 <- DALEX::explain(best_h2o,x_dalex,y_dalex,label = "h20_model")
explainer_log_reg <- DALEX::explain(logistic_regression, data=x_dalex, y=y_dalex, label="logistic_reg")
explainer_rf <- explain(random_forest,x_dalex,y_dalex,label ="random_forest")

mp_h2o <- model_performance(explainer_h20)
mp_log_reg <- model_performance(explainer_log_reg)
mp_rf <- model_performance(explainer_rf)
```

```{r}
plot(mp_h2o,mp_log_reg,mp_rf)
plot(mp_h2o,mp_log_reg,mp_rf, geom = "boxplot")
```

## Feature Importance

```{r}
fi_h20 <- feature_importance(explainer_h20)
fi_log_reg <- feature_importance(explainer_log_reg)
fi_rf <- feature_importance(explainer_rf)

describe(fi_h20)
plot(fi_h20,fi_log_reg,fi_rf)
```

## Variable explanation

### Accumulated Local Effects Profiles aka ALEPlots

Nota atribuída com respeito ao comprometimento da operadora em cumprir o que foi prometido e divulgado em sua publicidade.

```{r}
adp_h2o <- accumulated_dependency(explainer_h20,variables = "B1_2")
adp_log_reg <- accumulated_dependency(explainer_log_reg,variables = "B1_2")
adp_rf <- accumulated_dependency(explainer_rf,variables = "B1_2")

plot(adp_h2o,adp_log_reg,adp_rf)
```


### Factor explanation

G1: Existência de outra operadora que ofereça o mesmo serviço da atual, no local onde o entrevistado mora:

1. Sim
2. Não
3. Não sabe


```{r}
expl_h2o <- variable_response(explainer_h20,variable = "G1", type = "factor")
expl_log_reg <- variable_response(explainer_log_reg,variable = "G1", type = "factor")
expl_rf<- variable_response(explainer_rf,variable = "G1", type = "factor")

plot(expl_h2o,expl_log_reg,expl_rf)
```

## Single prediction explanation 

```{r}
bd_h2o <- break_down(explainer_h20, x_dalex[1,])
bd_log_reg <- break_down(explainer_log_reg, x_dalex[1,])
bd_rf <- break_down(explainer_rf, x_dalex[1,])

plot(bd_h2o)
plot(bd_log_reg)
plot(bd_rf)
```
